[{
  "id": 87,
  "gmtCreate": 1646306448266,
  "gmtModified": 1646306448266,
  "creator": "",
  "operator": "",
  "appId": "",
  "name": "oem_pod_event_collect",
  "alias": "POD事件明细采集作业(内置)",
  "tags": ["pod", "event", "oem"],
  "description": null,
  "options": null,
  "triggerType": "cron",
  "triggerConf": {
    "cronExpression": "10 * * * * ? *",
    "enabled": true
  },
  "scheduleType": "serial",
  "scheduleConf": {
    "taskIdList": [{
      "id": 84,
      "gmtCreate": 1646306448259,
      "gmtModified": 1646306448259,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_pod_event",
      "alias": "POD事件明细(内置)",
      "execTimeout": 60,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport json\nimport time\nimport requests\n\nheaders = {}\n\npage_size = 1000\none_millisecond = 1000\none_minutes_millisecond = 60000\n\nhost = {\n    \"dataset\": \"http://prod-dataops-dataset.sreworks-dataops.svc.cluster.local:80\"\n}\n\n\ndef get_time_range(ts, delta_ts, forward_gap=0):\n    \"\"\"\n    时间范围\n    :param ts:\n    :param delta_ts:\n    :param forward_gap: 默认前推一个delta\n    :return:\n    \"\"\"\n    ts_integer = int(ts)\n    delta_ts_integer = int(delta_ts)\n\n    end_ts = ts_integer - ts_integer % delta_ts_integer\n    start_ts = end_ts - delta_ts_integer\n\n    delta_forward_ts_integer = delta_ts_integer * forward_gap\n\n    return start_ts - delta_forward_ts_integer, end_ts - delta_forward_ts_integer\n\n\ndef get_pod_events():\n    endpoint = host[\"dataset\"] + \"/interface/kubernetes_event\"\n    start_timestamp, end_timestamp = get_time_range(time.time() * one_millisecond, one_minutes_millisecond)\n    basic_url = f'''{endpoint}?sTimestamp={start_timestamp}&eTimestamp={end_timestamp}&kind=Pod'''\n\n    page_num = 1\n    events = []\n    while True:\n        url = basic_url + \"&pageNum=\" + str(page_num)\n        r = requests.get(url, headers=headers)\n        if r.status_code != 200:\n            break\n\n        ret = r.json().get(\"data\", None)\n        if ret and ret.get(\"datas\"):\n            events.extend(ret.get(\"datas\"))\n            _total_num = int(ret.get(\"totalNum\"))\n            _page_size = int(ret.get(\"pageSize\"))\n            _page_num = int(ret.get(\"pageNum\"))\n            if _page_size > _total_num:\n                break\n            else:\n                page_num = _page_num + 1\n        else:\n            break\n\n    uid_set = set([])\n    de_duplicate_events = []\n    for event in events:\n        uid = event.get('uid')\n        if uid not in uid_set:\n            uid_set.add(uid)\n            ts = int(time.time() * one_millisecond)\n            event[\"id\"] = uid + \"_\" + str(ts)\n            event[\"podName\"] = event[\"name\"]\n            event[\"timestamp\"] = ts\n            de_duplicate_events.append(event)\n    return de_duplicate_events\n\n\nprint(json.dumps(get_pod_events()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 116,
        "type": "model",
        "layer": "dwd"
      }
    }]
  },
  "sceneType": "collect",
  "sceneConf": {},
  "varConf": {},
  "notifyConf": null,
  "eventConf": []
}, {
  "id": 88,
  "gmtCreate": 1646306448345,
  "gmtModified": 1646381024765,
  "creator": "",
  "operator": "999999999",
  "appId": "",
  "name": "oem_app_delivery_deployment_collect",
  "alias": "应用构建部署明细采集作业(内置)",
  "tags": ["delivery", "deployment"],
  "description": null,
  "options": null,
  "triggerType": "cron",
  "triggerConf": {
    "cronExpression": "0 1 * * * ? *",
    "enabled": true
  },
  "scheduleType": "serial",
  "scheduleConf": {
    "taskIdList": [{
      "id": 85,
      "gmtCreate": 1646306448334,
      "gmtModified": 1646306448334,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_delivery",
      "alias": "应用交付构建明细(内置)",
      "execTimeout": 60,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport datetime\nimport json\nimport time\n\nimport requests\n\nheaders = {}\nhost = {\n    \"dataset\": \"http://prod-dataops-dataset.sreworks-dataops.svc.cluster.local:80\"\n}\n\npage_size = 1000\none_second_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\n\ndef convert_utc_to_local_dt(str_utc_time):\n    # return datetime.datetime.strptime(str_utc_time, \"%Y-%m-%dT%H:%M:%S.%fZ\").replace(tzinfo=datetime.timezone.utc).astimezone(tz.tzlocal())\n    return datetime.datetime.strptime(str_utc_time, \"%Y-%m-%dT%H:%M:%S.%fZ\").replace(tzinfo=datetime.timezone.utc) \\\n        .astimezone(datetime.timezone(datetime.timedelta(hours=8)))\n\n\ndef _do_get_sreworks_action(action_label):\n    # now_utc_dt = datetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc)\n    # now_day_utc_dt = now_utc_dt.replace(hour=0, minute=0, second=0, microsecond=0)\n    dt = datetime.datetime.now()\n    start_ds = dt.strftime(\"%Y%m%d\")\n    now_timestamp = int(time.time()) * one_second_millisecond\n    end_timestamp = now_timestamp - now_timestamp % one_hour_millisecond\n    start_timestamp = end_timestamp - one_hour_millisecond\n\n    query = f\"start_time:[{start_timestamp} TO {end_timestamp}] AND action_label:{action_label}\"\n    basic_url = host[\"dataset\"] + f'''/interface/action?query={query}&pageSize={page_size}'''\n    page_num = 1\n    datas = []\n    while True:\n        url = basic_url + \"&pageNum=\" + str(page_num)\n        r = requests.get(url, headers=headers)\n        if r.status_code != 200:\n            break\n\n        ret = r.json().get(\"data\", None)\n        if ret and ret.get(\"datas\"):\n            datas.extend(ret.get(\"datas\"))\n            _total_num = int(ret.get(\"totalNum\"))\n            _page_size = int(ret.get(\"pageSize\"))\n            _page_num = int(ret.get(\"pageNum\"))\n            if _page_size > _total_num:\n                break\n            else:\n                page_num = _page_num + 1\n        else:\n            break\n\n    return datas, start_ds\n\n\ndef get_sreworks_action():\n    actions, start_ds = _do_get_sreworks_action(\"应用构建\")\n    deliveries = []\n    for action in actions:\n        exec_data = action[\"exec_data\"]\n        params = action[\"action_meta_data\"].get(\"params\", {})\n        if \"appId\" in params and \"teamId\" in params:\n            delivery = {\n                \"id\": exec_data[\"data\"][\"appPackageTaskId\"],\n                \"appId\": params[\"appId\"],\n                \"teamId\": params[\"teamId\"],\n                \"version\": params[\"build_version\"],\n                \"status\": exec_data[\"status\"],\n                \"startTime\": action[\"start_time\"],\n                \"endTime\": action[\"end_time\"],\n                \"ds\": start_ds\n            }\n            deliveries.append(delivery)\n\n    return deliveries\n\n\nprint(json.dumps(get_sreworks_action()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 112,
        "type": "model",
        "layer": "dwd"
      }
    }, {
      "id": 86,
      "gmtCreate": 1646306448340,
      "gmtModified": 1646306448340,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_deployment",
      "alias": "应用部署明细(内置)",
      "execTimeout": 60,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport time\nimport datetime\nimport json\nimport requests\n\nheaders = {}\nhost = {\n    \"dataset\": \"http://prod-dataops-dataset.sreworks-dataops.svc.cluster.local:80\",\n    \"app\": \"http://prod-app-app.sreworks.svc.cluster.local:80\"\n}\n\n\npage_size = 1000\none_second_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\n\ndef get_app_instances():\n    endpoint = host[\"app\"] + \"/appcenter/appInstance/allAppInstances?page=1&pageSize=1000000\"\n    r = requests.get(endpoint, headers=headers)\n    datas = r.json().get(\"data\", None)\n    app_instances = {}\n    if datas:\n        for data in datas[\"items\"]:\n            app_instances[data[\"appInstanceName\"]] = data[\"appInstanceId\"]\n    return app_instances\n\n\ndef _do_get_sreworks_action(action_label):\n    dt = datetime.datetime.now()\n    start_ds = dt.strftime(\"%Y%m%d\")\n    now_timestamp = int(time.time()) * one_second_millisecond\n    end_timestamp = now_timestamp - now_timestamp % one_hour_millisecond\n    start_timestamp = end_timestamp - one_hour_millisecond\n\n    query = f\"start_time:[{start_timestamp} TO {end_timestamp}] AND action_label:{action_label}\"\n    basic_url = host[\"dataset\"] + f'''/interface/action?query={query}&pageSize={page_size}'''\n    page_num = 1\n    datas = []\n    while True:\n        url = basic_url + \"&pageNum=\" + str(page_num)\n        r = requests.get(url, headers=headers)\n        if r.status_code != 200:\n            break\n\n        ret = r.json().get(\"data\", None)\n        if ret and ret.get(\"datas\"):\n            datas.extend(ret.get(\"datas\"))\n            _total_num = int(ret.get(\"totalNum\"))\n            _page_size = int(ret.get(\"pageSize\"))\n            _page_num = int(ret.get(\"pageNum\"))\n            if _page_size > _total_num:\n                break\n            else:\n                page_num = _page_num + 1\n        else:\n            break\n\n    return datas, start_ds\n\n\ndef get_sreworks_action():\n    actions, start_ds = _do_get_sreworks_action(\"应用部署\")\n    app_instance_dict = get_app_instances()\n    deployments = []\n    for action in actions:\n        exec_data = action[\"exec_data\"]\n        params = action[\"action_meta_data\"].get(\"params\", {})\n        app_instance_name = params.get(\"appInstanceName\", None)\n        if app_instance_name in app_instance_dict:\n            deployment = {\n                \"id\": exec_data[\"data\"][\"deployAppId\"],\n                \"appId\": params[\"appId\"],\n                \"appInstanceId\": app_instance_dict[app_instance_name],\n                \"appInstanceName\": app_instance_name,\n                \"appName\": params[\"appName\"],\n                \"clusterId\": params[\"clusterId\"],\n                \"namespace\": params[\"namespaceId\"],\n                \"teamId\": params[\"teamId\"],\n                \"version\": params[\"simplePackageVersion\"],\n                \"status\": exec_data[\"status\"],\n                \"startTime\": action[\"start_time\"],\n                \"endTime\": action[\"end_time\"],\n                \"ds\": start_ds\n            }\n            deployments.append(deployment)\n\n    return deployments\n\n\nprint(json.dumps(get_sreworks_action()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 113,
        "type": "model",
        "layer": "dwd"
      }
    }]
  },
  "sceneType": "collect",
  "sceneConf": {},
  "varConf": {},
  "notifyConf": null,
  "eventConf": []
}, {
  "id": 89,
  "gmtCreate": 1646306448396,
  "gmtModified": 1646306448396,
  "creator": "",
  "operator": "",
  "appId": "",
  "name": "oem_app_delivery_deployment_stats_collect",
  "alias": "应用构建部署统计采集作业(内置)",
  "tags": ["delivery", "deployment", "stats"],
  "description": null,
  "options": null,
  "triggerType": "cron",
  "triggerConf": {
    "cronExpression": "0 0 1 * * ? *",
    "enabled": true
  },
  "scheduleType": "serial",
  "scheduleConf": {
    "taskIdList": [{
      "id": 87,
      "gmtCreate": 1646306448381,
      "gmtModified": 1646306448381,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_delivery_deployment_quality",
      "alias": "应用构建部署质量统计(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport datetime\nimport json\nimport requests\n\nheaders = {}\nhost = {\n    \"dataset\": \"http://prod-dataops-dataset.sreworks-dataops.svc.cluster.local:80\",\n    \"app\": \"http://prod-app-app.sreworks.svc.cluster.local:80\"\n}\n\npage_size = 1000\none_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\n\ndef get_app_instances():\n    endpoint = host[\"app\"] + \"/appcenter/appInstance/allAppInstances?page=1&pageSize=1000000\"\n    r = requests.get(endpoint, headers=headers)\n    datas = r.json().get(\"data\", None)\n    app_instances = {}\n    if datas:\n        for data in datas[\"items\"]:\n            app_instances[data[\"appInstanceName\"]] = data\n    return app_instances\n\n\ndef _do_get_sreworks_action(action_label):\n    dt = datetime.datetime.now()\n    yesterday_dt = dt + datetime.timedelta(days=-1)\n    start_ds = yesterday_dt.strftime(\"%Y%m%d\")\n\n    now_day_dt = dt.replace(hour=0, minute=0, second=0, microsecond=0)\n    end_timestamp = int(now_day_dt.timestamp()) * one_millisecond\n    start_timestamp = end_timestamp - 86400000\n\n    query = f\"start_time:[{start_timestamp} TO {end_timestamp}] AND action_label:{action_label}\"\n    basic_url = host[\"dataset\"] + f'''/interface/action?query={query}&pageSize={page_size}'''\n    page_num = 1\n    datas = []\n    while True:\n        url = basic_url + \"&pageNum=\" + str(page_num)\n        r = requests.get(url, headers=headers)\n        if r.status_code != 200:\n            break\n\n        ret = r.json().get(\"data\", None)\n        if ret and ret.get(\"datas\"):\n            datas.extend(ret.get(\"datas\"))\n            _total_num = int(ret.get(\"totalNum\"))\n            _page_size = int(ret.get(\"pageSize\"))\n            _page_num = int(ret.get(\"pageNum\"))\n            if _page_size > _total_num:\n                break\n            else:\n                page_num = _page_num + 1\n        else:\n            break\n\n    return datas, start_ds, start_timestamp\n\n\ndef get_sreworks_action():\n    delivery_actions, start_ds, start_timestamp = _do_get_sreworks_action(\"应用构建\")\n    deployment_actions, start_ds, start_timestamp = _do_get_sreworks_action(\"应用部署\")\n    app_instance_dict = get_app_instances()\n\n    deliveries = {}\n    for action in delivery_actions:\n        exec_data = action[\"exec_data\"]\n        params = action[\"action_meta_data\"].get(\"params\", {})\n        if \"appId\" in params and \"teamId\" in params:\n            app_id = params[\"appId\"]\n            if app_id in deliveries:\n                delivery = deliveries[app_id]\n                delivery[\"cnt\"] += 1\n                delivery[\"successCnt\"] = delivery[\"successCnt\"] + 1 if exec_data[\"status\"] == \"SUCCESS\" else delivery[\"successCnt\"]\n                delivery[\"successRate\"] = delivery[\"successCnt\"] / delivery[\"cnt\"]\n            else:\n                success_cnt = 1 if exec_data[\"status\"] == \"SUCCESS\" else 0\n                delivery = {\n                    \"appId\": params[\"appId\"],\n                    \"teamId\": params[\"teamId\"],\n                    \"cnt\": 1,\n                    \"successCnt\": success_cnt,\n                    \"successRate\": success_cnt / 1\n                }\n                deliveries[app_id] = delivery\n\n    deployments = {}\n    for action in deployment_actions:\n        exec_data = action[\"exec_data\"]\n        params = action[\"action_meta_data\"].get(\"params\", {})\n        app_instance_name = params.get(\"appInstanceName\", None)\n        if app_instance_name in deployments:\n            deployment = deployments[app_instance_name]\n            deployment[\"cnt\"] += 1\n            deployment[\"successCnt\"] = deployment[\"successCnt\"] + 1 if exec_data[\"status\"] == \"SUCCESS\" else deployment[\"successCnt\"]\n            deployment[\"successRate\"] = deployment[\"successCnt\"] / deployment[\"cnt\"]\n        else:\n            success_cnt = 1 if exec_data[\"status\"] == \"SUCCESS\" else 0\n            deployment = {\n                \"appId\": params[\"appId\"],\n                \"appInstanceName\": app_instance_name,\n                \"appName\": params[\"appName\"],\n                \"teamId\": params[\"teamId\"],\n                \"cnt\": 1,\n                \"successCnt\": success_cnt,\n                \"successRate\": success_cnt / 1\n            }\n            deployments[app_instance_name] = deployment\n\n    qualities = []\n    for app_instance_name, app_instance in app_instance_dict.items():\n        deployment = deployments.get(app_instance_name, {})\n        app_id = app_instance[\"appId\"]\n        app_instance_id = app_instance[\"appInstanceId\"]\n        delivery = deliveries.get(app_id, {})\n        team_id = deployment.get(\"teamId\", None) if deployment.get(\"teamId\", None) else app_instance[\"team\"][\"team_id\"]\n\n        quality = {\n            \"id\": app_instance_id,\n            \"ds\": start_ds,\n            \"appId\": app_id,\n            \"appInstanceId\": app_instance_id,\n            \"appInstanceName\": app_instance_name,\n            \"teamId\": team_id,\n            \"deliveryCntDailyAdditions\": delivery.get(\"cnt\", 0),\n            \"deliverySuccessCntDailyAdditions\": delivery.get(\"successCnt\", 0),\n            \"deliverySuccessRateDaily\": delivery.get(\"successRate\", 1),\n            \"deploymentCntDailyAdditions\": deployment.get(\"cnt\", 0),\n            \"deploymentSuccessCntDailyAdditions\": deployment.get(\"successCnt\", 0),\n            \"deploymentSuccessRateDaily\": deployment.get(\"successRate\", 1),\n            \"timestamp\": start_timestamp\n        }\n        qualities.append(quality)\n\n    return qualities\n\n\nprint(json.dumps(get_sreworks_action()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 114,
        "type": "model",
        "layer": "ads"
      }
    }, {
      "id": 88,
      "gmtCreate": 1646306448391,
      "gmtModified": 1646306448391,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_delivery_deployment_efficiency",
      "alias": "应用构建部署效率统计(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport datetime\nimport json\nimport time\n\nimport requests\n\nheaders = {}\nhost = {\n    \"dataset\": \"http://prod-dataops-dataset.sreworks-dataops.svc.cluster.local:80\",\n}\n\naccount_super_client_id = \"common\"\naccount_super_id = \"admin\"\naccount_super_client_secret = \"common-9efab2399c7c560b34de477b9aa0a465\"\naccount_super_secret_key = \"test-super-secret-key\"\n\npage_size = 1000\none_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\n\ndef _retry_get_request(url):\n    ret = {}\n\n    max_retry_times = 3\n    cur_retry_time = 0\n    while cur_retry_time < max_retry_times:\n        cur_retry_time += 1\n        r = requests.get(url, headers=headers)\n        if r.status_code == 200:\n            ret = r.json().get(\"data\", {})\n            break\n        time.sleep(10)\n\n    return ret\n\n\ndef _do_query_dataset_interface(basic_url):\n    page_num = 1\n    datas = []\n    while True:\n        url = basic_url + \"&pageNum=\" + str(page_num)\n        ret = _retry_get_request(url)\n        if ret and ret.get(\"datas\"):\n            datas.extend(ret.get(\"datas\"))\n            _total_num = int(ret.get(\"totalNum\"))\n            _page_size = int(ret.get(\"pageSize\"))\n            _page_num = int(ret.get(\"pageNum\"))\n            if _page_size > _total_num:\n                break\n            else:\n                page_num = _page_num + 1\n        else:\n            break\n\n    return datas\n\n\ndef get_dd_efficiency():\n    team_user_url = host[\"dataset\"] + f'''/interface/team_user?pageSize={page_size}'''\n    team_users = _do_query_dataset_interface(team_user_url)\n\n    team_user_cnt = {}\n    for team_user in team_users:\n        team_id = team_user[\"teamId\"]\n        if team_id in team_user_cnt:\n            team_user_cnt[team_id] += 1\n        else:\n            team_user_cnt[team_id] = 1\n\n    dt = datetime.datetime.now()\n    yesterday_dt = dt + datetime.timedelta(days=-1)\n    start_ds = yesterday_dt.strftime(\"%Y%m%d\")\n\n    now_day_dt = dt.replace(hour=0, minute=0, second=0, microsecond=0)\n    end_timestamp = int(now_day_dt.timestamp()) * one_millisecond\n    start_timestamp = end_timestamp - 86400000\n\n    dd_quality_url = host[\"dataset\"] + f'''/interface/app_delivery_deployment_quality?sTimestamp={start_timestamp}&eTimestamp={end_timestamp}&pageSize={page_size}'''\n    dd_qualities = _do_query_dataset_interface(dd_quality_url)\n\n    efficiencies = []\n    for quality in dd_qualities:\n        team_id = quality[\"teamId\"]\n        team_member_cnt = team_user_cnt[team_id]\n        efficiency = {\n            \"id\": quality[\"appInstanceId\"],\n            \"ds\": start_ds,\n            \"appId\": quality[\"appId\"],\n            \"appInstanceId\": quality[\"appInstanceId\"],\n            \"appInstanceName\": quality[\"appInstanceName\"],\n            \"teamId\": team_id,\n            \"teamMemberCnt\": team_member_cnt,\n            \"deliveryCntDailyAdditions\": quality[\"deliveryCntDailyAdditions\"],\n            \"deploymentCntDailyAdditions\": quality[\"deploymentCntDailyAdditions\"],\n            \"hrEffectivenessRatioDaily\": (quality[\"deploymentCntDailyAdditions\"] + quality[\"deliveryCntDailyAdditions\"]) / team_member_cnt,\n            \"timestamp\": start_timestamp\n        }\n        efficiencies.append(efficiency)\n    return efficiencies\n\n\nprint(json.dumps(get_dd_efficiency()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 115,
        "type": "model",
        "layer": "ads"
      }
    }]
  },
  "sceneType": "collect",
  "sceneConf": {},
  "varConf": {},
  "notifyConf": null,
  "eventConf": []
}, {
  "id": 90,
  "gmtCreate": 1646306448458,
  "gmtModified": 1646306448458,
  "creator": "",
  "operator": "",
  "appId": "",
  "name": "oem_app_resource_allocated_cost_stats_collect",
  "alias": "应用资源分配成本统计采集作业(内置)",
  "tags": ["app", "resource", "cost", "stats"],
  "description": "应用资源分配成本统计采集作业(内置)",
  "options": null,
  "triggerType": "cron",
  "triggerConf": {
    "cronExpression": "0 30 0 * * ? *",
    "enabled": true
  },
  "scheduleType": "serial",
  "scheduleConf": {
    "taskIdList": [{
      "id": 89,
      "gmtCreate": 1646306448434,
      "gmtModified": 1646306448434,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_cluster_resource_price",
      "alias": "集群计费维度数据(内置)",
      "execTimeout": 30,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport json\nimport requests\n\nheaders = {}\nhost = {\n    \"dataset\": \"http://prod-dataops-dataset.sreworks-dataops.svc.cluster.local:80\"\n}\n\npage_size = 1000\n\n\ndef _get_data_by_interface(basic_url):\n    page_num = 1\n    datas = []\n    while True:\n        url = basic_url + \"&pageNum=\" + str(page_num)\n        r = requests.get(url, headers=headers)\n        if r.status_code == 200:\n            ret = r.json().get(\"data\", None)\n            if ret is not None:\n                datas.extend(ret.get(\"datas\"))\n                _total_num = int(ret.get(\"totalNum\"))\n                _page_size = int(ret.get(\"pageSize\"))\n                _page_num = int(ret.get(\"pageNum\"))\n                if _page_size > _total_num:\n                    break\n                else:\n                    page_num = _page_num + 1\n    return datas\n\n\ndef get_resource_prices():\n    endpoint_resource_price = host[\"dataset\"] + \"/interface/resource_price\"\n    basic_url = f'''{endpoint_resource_price}?pageSize={page_size}'''\n    return _get_data_by_interface(basic_url)\n\n\nprint(json.dumps(get_resource_prices()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 110,
        "type": "model",
        "layer": "dim"
      }
    }, {
      "id": 90,
      "gmtCreate": 1646306448440,
      "gmtModified": 1646306448440,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_pod_resource_allocated_1d",
      "alias": "应用POD天级别资源分配(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport datetime\nimport json\nimport requests\n\nheaders = {}\nhost = {\n    \"dataset\": \"http://prod-dataops-dataset.sreworks-dataops.svc.cluster.local:80\"\n}\n\npage_size = 1000\none_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\n\ndef _do_get_pod_resource_allocated(endpoint, start_timestamp, end_timestamp):\n    basic_url = f'''{endpoint}?sTimestamp={start_timestamp}&eTimestamp={end_timestamp}&pageSize={page_size}'''\n    page_num = 1\n    datas = []\n    while True:\n        url = basic_url + \"&pageNum=\" + str(page_num)\n        r = requests.get(url, headers=headers)\n        if r.status_code != 200:\n            break\n\n        ret = r.json().get(\"data\", None)\n        if ret and ret.get(\"datas\"):\n            datas.extend(ret.get(\"datas\"))\n            _total_num = int(ret.get(\"totalNum\"))\n            _page_size = int(ret.get(\"pageSize\"))\n            _page_num = int(ret.get(\"pageNum\"))\n            if _page_size > _total_num:\n                break\n            else:\n                page_num = _page_num + 1\n        else:\n            break\n\n    return datas\n\n\ndef get_pod_resource_allocated():\n    dt = datetime.datetime.now()\n    yesterday_dt = dt + datetime.timedelta(days=-1)\n    start_ds = yesterday_dt.strftime(\"%Y%m%d\")\n\n    now_day_dt = dt.replace(hour=0, minute=0, second=0, microsecond=0)\n    end_timestamp = int(now_day_dt.timestamp()) * one_millisecond\n    start_timestamp = end_timestamp - 86400000\n\n    endpoint_cpu_core = host[\"dataset\"] + \"/interface/pod_resource_hours_allocation\"\n    pod_resource_allocation_list = _do_get_pod_resource_allocated(endpoint_cpu_core, start_timestamp, end_timestamp)\n\n    result = {}\n    for pod_resource_allocation in pod_resource_allocation_list:\n        namespace = pod_resource_allocation[\"namespace\"]\n        pod_name = pod_resource_allocation[\"podName\"]\n        key = namespace + \"#\" + pod_name\n\n        pod_ram_gb_hours_allocation = 0 if pod_resource_allocation[\"podRamGbHoursAllocation\"] is None else pod_resource_allocation[\"podRamGbHoursAllocation\"]\n        pod_cpu_core_hours_allocation = 0 if pod_resource_allocation[\"podCpuCoreHoursAllocation\"] is None else pod_resource_allocation[\"podCpuCoreHoursAllocation\"]\n        pod_pvc_gb_hours_allocation = 0 if pod_resource_allocation[\"podPVCGbHoursAllocation\"] is None else pod_resource_allocation[\"podPVCGbHoursAllocation\"]\n        pod_cpu_core_hours_usage_avg = 0 if pod_resource_allocation[\"podCpuCoreHoursUsageAvg\"] is None else pod_resource_allocation[\"podCpuCoreHoursUsageAvg\"]\n        pod_ram_gb_hours_usage_avg = 0 if pod_resource_allocation[\"podRamGbHoursUsageAvg\"] is None else pod_resource_allocation[\"podRamGbHoursUsageAvg\"]\n        if key in result:\n            result[key][\"podRamGbAllocation\"] += pod_ram_gb_hours_allocation\n            result[key][\"podCpuCoreAllocation\"] += pod_cpu_core_hours_allocation\n            result[key][\"podPVCGbAllocation\"] += pod_pvc_gb_hours_allocation\n            result[key][\"podCpuCoreUsageAvg\"] += pod_cpu_core_hours_usage_avg\n            result[key][\"podRamGbUsageAvg\"] += pod_ram_gb_hours_usage_avg\n            result[key][\"ramEfficiency\"] = 1.0 if result[key][\"podRamGbAllocation\"] == 0 or result[key][\"podRamGbUsageAvg\"]>= result[key][\"podRamGbAllocation\"] else result[key][\"podRamGbUsageAvg\"] / result[key][\"podRamGbAllocation\"]\n            result[key][\"cpuEfficiency\"] = 1.0 if result[key][\"podCpuCoreAllocation\"] == 0 or result[key][\"podCpuCoreUsageAvg\"] >= result[key][\"podCpuCoreAllocation\"] else result[key][\"podCpuCoreUsageAvg\"] / result[key][\"podCpuCoreAllocation\"]\n        else:\n            result[key] = {\n                \"appInstanceId\": pod_resource_allocation[\"appInstanceId\"],\n                \"appComponentInstanceId\": pod_resource_allocation[\"appComponentInstanceId\"],\n                \"appId\": pod_resource_allocation[\"appId\"],\n                \"namespace\": pod_resource_allocation[\"namespace\"],\n                \"appComponentName\": pod_resource_allocation[\"appComponentName\"],\n                \"podName\": pod_resource_allocation[\"podName\"],\n                \"clusterId\": pod_resource_allocation[\"clusterId\"],\n                \"appInstanceName\": pod_resource_allocation[\"appInstanceName\"],\n                \"podRamGbAllocation\": pod_ram_gb_hours_allocation,\n                \"podCpuCoreAllocation\": pod_cpu_core_hours_allocation,\n                \"podPVCGbAllocation\": pod_pvc_gb_hours_allocation,\n                \"podCpuCoreUsageAvg\": pod_cpu_core_hours_usage_avg,\n                \"podRamGbUsageAvg\": pod_ram_gb_hours_usage_avg,\n                \"ramEfficiency\": 1.0 if pod_ram_gb_hours_allocation == 0 or pod_ram_gb_hours_usage_avg >= pod_ram_gb_hours_allocation else pod_ram_gb_hours_usage_avg/pod_ram_gb_hours_allocation,\n                \"cpuEfficiency\": 1.0 if pod_cpu_core_hours_allocation == 0 or pod_cpu_core_hours_usage_avg >= pod_cpu_core_hours_allocation else pod_cpu_core_hours_usage_avg/pod_cpu_core_hours_allocation,\n                \"ds\": start_ds,\n                \"id\": key,\n                \"timestamp\": start_timestamp\n            }\n    return list(result.values())\n\n\nprint(json.dumps(get_pod_resource_allocated()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 92,
        "type": "model",
        "layer": "dws"
      }
    }, {
      "id": 91,
      "gmtCreate": 1646306448448,
      "gmtModified": 1646306448448,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_resource_allocated_cost_1d",
      "alias": "应用天级别资源分配成本(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport datetime\nimport json\nimport time\n\nimport requests\n\nheaders = {}\nhost = {\n    \"dataset\": \"http://prod-dataops-dataset.sreworks-dataops.svc.cluster.local:80\"\n}\n\npage_size = 1000\none_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\nmonthly_hours = 730\n\n\ndef _retry_get_request(url):\n    ret = {}\n\n    max_retry_times = 3\n    cur_retry_time = 0\n    while cur_retry_time < max_retry_times:\n        cur_retry_time += 1\n        r = requests.get(url, headers=headers)\n        if r.status_code == 200:\n            ret = r.json().get(\"data\", {})\n            break\n        time.sleep(10)\n\n    return ret\n\n\ndef _get_data_by_interface(basic_url):\n    page_num = 1\n    datas = []\n    while True:\n        url = basic_url + \"&pageNum=\" + str(page_num)\n        ret = _retry_get_request(url)\n        if ret and ret.get(\"datas\"):\n            datas.extend(ret.get(\"datas\"))\n            _total_num = int(ret.get(\"totalNum\"))\n            _page_size = int(ret.get(\"pageSize\"))\n            _page_num = int(ret.get(\"pageNum\"))\n            if _page_size > _total_num:\n                break\n            else:\n                page_num = _page_num + 1\n        else:\n            break\n\n    return datas\n\n\ndef get_pod_resource_allocated():\n    dt = datetime.datetime.now()\n    yesterday_dt = dt + datetime.timedelta(days=-1)\n    start_ds = yesterday_dt.strftime(\"%Y%m%d\")\n\n    now_day_dt = dt.replace(hour=0, minute=0, second=0, microsecond=0)\n    end_timestamp = int(now_day_dt.timestamp()) * one_millisecond\n    start_timestamp = end_timestamp - 86400000\n\n    endpoint_pod_resource = host[\"dataset\"] + \"/interface/pod_resource_allocation_stats\"\n    basic_url = f'''{endpoint_pod_resource}?sTimestamp={start_timestamp}&eTimestamp={end_timestamp}&pageSize={page_size}'''\n    pod_resource_allocation_list = _get_data_by_interface(basic_url)\n\n    endpoint_resource_price = host[\"dataset\"] + \"/interface/resource_price\"\n    basic_url = f'''{endpoint_resource_price}?pageSize={page_size}'''\n    resource_price_list = _get_data_by_interface(basic_url)\n\n    cluster_price = {}\n    for resource_price in resource_price_list:\n        cluster_id = resource_price.get(\"clusterId\", \"default\")\n        cluster_price[cluster_id] = resource_price\n\n    app_resource_allocation = {}\n    for pod_resource_allocation in pod_resource_allocation_list:\n        cluster_id = pod_resource_allocation[\"clusterId\"]\n        if cluster_id not in cluster_price:\n            cluster_id = \"default\"\n        resource_price = cluster_price[cluster_id]\n\n        cpu_cost = (resource_price[\"monthlyCpuPrice\"]/730) * pod_resource_allocation[\"podCpuCoreAllocation\"]\n        ram_cost = (resource_price[\"monthlyRamPrice\"]/730) * pod_resource_allocation[\"podRamGbAllocation\"]\n        pvc_cost = (resource_price[\"monthlyStoragePrice\"]/730) * pod_resource_allocation[\"podPVCGbAllocation\"]\n\n        app_instance_id = pod_resource_allocation[\"appInstanceId\"]\n        if app_instance_id in pod_resource_allocation:\n            res = app_resource_allocation[app_instance_id]\n            res[\"cpuCoreAllocation\"] += pod_resource_allocation[\"podCpuCoreAllocation\"]\n            res[\"ramGbAllocation\"] += pod_resource_allocation[\"podRamGbAllocation\"]\n            res[\"pvcGbAllocation\"] += pod_resource_allocation[\"podPVCGbAllocation\"]\n            res[\"cpuCoreUsageAvg\"] += pod_resource_allocation[\"podCpuCoreUsageAvg\"]\n            res[\"ramGbUsageAvg\"] += pod_resource_allocation[\"podRamGbUsageAvg\"]\n            res[\"ramEfficiency\"] = 1.0 if res[\"ramGbAllocation\"] == 0 or res[\"ramGbUsageAvg\"] >= res[\"ramGbAllocation\"] else res[\"ramGbUsageAvg\"] / res[\"ramGbAllocation\"]\n            res[\"cpuEfficiency\"] = 1.0 if res[\"cpuCoreAllocation\"] == 0 or res[\"cpuCoreUsageAvg\"] >= res[\"cpuCoreAllocation\"] else res[\"cpuCoreUsageAvg\"] / res[\"cpuCoreAllocation\"]\n\n            res[\"cpuCost\"] += cpu_cost\n            res[\"ramCost\"] += ram_cost\n            res[\"pvcCost\"] += pvc_cost\n            res[\"cost\"] += cpu_cost + ram_cost + pvc_cost\n            res[\"podCnt\"] += 1\n        else:\n            app_resource_allocation[app_instance_id] = {\n                \"appId\": pod_resource_allocation[\"appId\"],\n                \"appInstanceId\": pod_resource_allocation[\"appInstanceId\"],\n                \"cpuCoreAllocation\": pod_resource_allocation[\"podCpuCoreAllocation\"],\n                \"ramGbAllocation\": pod_resource_allocation[\"podRamGbAllocation\"],\n                \"pvcGbAllocation\": pod_resource_allocation[\"podPVCGbAllocation\"],\n                \"cpuCoreUsageAvg\": pod_resource_allocation[\"podCpuCoreUsageAvg\"],\n                \"ramGbUsageAvg\": pod_resource_allocation[\"podRamGbUsageAvg\"],\n                \"ramEfficiency\": 1.0 if pod_resource_allocation[\"podRamGbAllocation\"] == 0 or pod_resource_allocation[\"podRamGbUsageAvg\"] >= pod_resource_allocation[\"podRamGbAllocation\"] else pod_resource_allocation[\"podRamGbUsageAvg\"]/pod_resource_allocation[\"podRamGbAllocation\"],\n                \"cpuEfficiency\": 1.0 if pod_resource_allocation[\"podCpuCoreAllocation\"] == 0 or pod_resource_allocation[\"podCpuCoreUsageAvg\"] >= pod_resource_allocation[\"podCpuCoreAllocation\"] else pod_resource_allocation[\"podCpuCoreUsageAvg\"]/pod_resource_allocation[\"podCpuCoreAllocation\"],\n                \"ds\": start_ds,\n                \"id\": pod_resource_allocation[\"appInstanceId\"],\n                \"cpuCost\": cpu_cost,\n                \"ramCost\": ram_cost,\n                \"pvcCost\": pvc_cost,\n                \"cost\": cpu_cost + ram_cost + pvc_cost,\n                \"timestamp\": start_timestamp,\n                \"currency\": resource_price[\"currency\"],\n                \"podCnt\": 1\n            }\n\n    return list(app_resource_allocation.values())\n\n\nprint(json.dumps(get_pod_resource_allocated()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 111,
        "type": "model",
        "layer": "ads"
      }
    }]
  },
  "sceneType": "collect",
  "sceneConf": {},
  "varConf": {},
  "notifyConf": null,
  "eventConf": []
}, {
  "id": 91,
  "gmtCreate": 1647512084218,
  "gmtModified": 1647512084218,
  "creator": "",
  "operator": "",
  "appId": "",
  "name": "oem_app_health_stats_collect",
  "alias": "应用健康统计采集作业(内置)",
  "tags": ["app", "health", "stats"],
  "description": null,
  "options": null,
  "triggerType": "cron",
  "triggerConf": {
    "cronExpression": "0 2 0 * * ? *",
    "enabled": true
  },
  "scheduleType": "serial",
  "scheduleConf": {
    "taskIdList": [{
      "id": 92,
      "gmtCreate": 1647512084186,
      "gmtModified": 1647591763765,
      "creator": "",
      "operator": "999999999",
      "appId": "",
      "name": "oem_app_risk_stats_1d",
      "alias": "应用天级别风险统计(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport datetime\nimport json\nimport requests\n\npage_size = 1000\none_second_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\nheaders = {}\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\",\n}\n\ncategory = \"risk\"\ninstance_path = {\n    \"risk\": \"/risk_instance/getRisks\",\n    \"alert\": \"/alert_instance/getAlerts\",\n    \"incident\": \"/incident_instance/getIncidents\",\n    \"failure\": \"/failure_instance/getFailures\"\n}\n\n\ndef get_definitions_group_by_component():\n    url = host[\"health\"] + \"/definition/getDefinitionsByCategory?category=\" + category\n    r = requests.get(url, headers=headers)\n    results = []\n    if r.status_code == 200:\n        results = r.json().get(\"data\", [])\n    datas = {}\n    for result in results:\n        key = result[\"appId\"]\n        if result.get(\"appComponentName\", None):\n            key = result[\"appId\"] + \"#\" + result[\"appComponentName\"]\n\n        if key in datas:\n            datas[key][\"cnt\"] += 1\n        else:\n            data = {\n                \"appId\": result[\"appId\"],\n                \"appComponentName\": result.get(\"appComponentName\", None),\n                \"cnt\": 1\n            }\n            datas[key] = data\n\n    return datas\n\n\ndef get_instances(s_timestamp, e_timestamp):\n    path = instance_path[category]\n    if s_timestamp is None and e_timestamp is None:\n        url = host[\"health\"] + path\n    else:\n        url = host[\"health\"] + path + \"?sTimestamp=\" + str(s_timestamp) + \"&eTimestamp=\" + str(e_timestamp)\n\n    r = requests.get(url, headers=headers)\n    results = []\n    if r.status_code == 200:\n        results = r.json().get(\"data\", [])\n    datas = {}\n    for result in results:\n        def_key = result[\"appId\"]\n        ins_key = result[\"appInstanceId\"]\n        if result.get(\"appComponentName\", None):\n            def_key = result[\"appId\"] + \"#\" + result[\"appComponentName\"]\n            ins_key = result[\"appInstanceId\"] + \"#\" + result[\"appComponentInstanceId\"]\n\n        if def_key in datas:\n            data = datas[def_key]\n            if ins_key in data:\n                data[ins_key][\"cnt\"] += 1\n            else:\n                item = {\n                    \"id\": ins_key,\n                    \"appId\": result[\"appId\"],\n                    \"appComponentName\": result.get(\"appComponentName\", None),\n                    \"appInstanceId\": result[\"appInstanceId\"],\n                    \"appComponentInstanceId\": result.get(\"appComponentInstanceId\", None),\n                    \"cnt\": 1\n                }\n                data[ins_key] = item\n        else:\n            item = {\n                \"id\": ins_key,\n                \"appId\": result[\"appId\"],\n                \"appComponentName\": result.get(\"appComponentName\", None),\n                \"appInstanceId\": result[\"appInstanceId\"],\n                \"appComponentInstanceId\": result.get(\"appComponentInstanceId\", None),\n                \"cnt\": 1\n            }\n            data = {\n                ins_key: item\n            }\n            datas[def_key] = data\n\n    return datas\n\n\ndef get_results():\n    dt = datetime.datetime.now()\n    yesterday_dt = dt + datetime.timedelta(days=-1)\n    start_ds = yesterday_dt.strftime(\"%Y%m%d\")\n\n    now_day_dt = dt.replace(hour=0, minute=0, second=0, microsecond=0)\n    end_timestamp = int(now_day_dt.timestamp()) * one_second_millisecond\n    start_timestamp = end_timestamp - 86400000\n\n    definitions_dict = get_definitions_group_by_component()\n    ins_daily_dict = get_instances(start_timestamp, end_timestamp)\n    ins_dict = get_instances(None, None)\n\n    results = []\n    for def_key, instance_dict in ins_dict.items():\n        for ins_key, instance in instance_dict.items():\n            result = instance\n            result[\"defCnt\"] = definitions_dict[def_key][\"cnt\"]\n            result[\"instanceCnt\"] = instance[\"cnt\"]\n            result[\"instanceCntDailyAdditions\"] = ins_daily_dict.get(def_key, {}).get(ins_key, {}).get(\"cnt\", 0)\n            result[\"timestamp\"] = start_timestamp\n            result[\"ds\"] = start_ds\n\n            results.append(result)\n    return results\n\n\nprint(json.dumps(get_results()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 86,
        "type": "model",
        "layer": "dws"
      }
    }, {
      "id": 93,
      "gmtCreate": 1647512084195,
      "gmtModified": 1647591795426,
      "creator": "",
      "operator": "999999999",
      "appId": "",
      "name": "oem_app_alert_stats_1d",
      "alias": "应用天级别告警统计(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport datetime\nimport json\nimport requests\n\npage_size = 1000\none_second_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\nheaders = {}\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\"\n}\n\ncategory = \"alert\"\ninstance_path = {\n    \"risk\": \"/risk_instance/getRisks\",\n    \"alert\": \"/alert_instance/getAlerts\",\n    \"incident\": \"/incident_instance/getIncidents\",\n    \"failure\": \"/failure_instance/getFailures\"\n}\n\n\ndef get_definitions_group_by_component():\n    url = host[\"health\"] + \"/definition/getDefinitionsByCategory?category=\" + category\n    r = requests.get(url, headers=headers)\n    results = []\n    if r.status_code == 200:\n        results = r.json().get(\"data\", [])\n    datas = {}\n    for result in results:\n        key = result[\"appId\"]\n        if result.get(\"appComponentName\", None):\n            key = result[\"appId\"] + \"#\" + result[\"appComponentName\"]\n\n        if key in datas:\n            datas[key][\"cnt\"] += 1\n        else:\n            data = {\n                \"appId\": result[\"appId\"],\n                \"appComponentName\": result.get(\"appComponentName\", None),\n                \"cnt\": 1\n            }\n            datas[key] = data\n\n    return datas\n\n\ndef get_instances(s_timestamp, e_timestamp):\n    path = instance_path[category]\n    if s_timestamp is None and e_timestamp is None:\n        url = host[\"health\"] + path\n    else:\n        url = host[\"health\"] + path + \"?sTimestamp=\" + str(s_timestamp) + \"&eTimestamp=\" + str(e_timestamp)\n\n    r = requests.get(url, headers=headers)\n    results = []\n    if r.status_code == 200:\n        results = r.json().get(\"data\", [])\n    datas = {}\n    for result in results:\n        def_key = result[\"appId\"]\n        ins_key = result[\"appInstanceId\"]\n        if result.get(\"appComponentName\", None):\n            def_key = result[\"appId\"] + \"#\" + result[\"appComponentName\"]\n            ins_key = result[\"appInstanceId\"] + \"#\" + result[\"appComponentInstanceId\"]\n\n        if def_key in datas:\n            data = datas[def_key]\n            if ins_key in data:\n                data[ins_key][\"cnt\"] += 1\n            else:\n                item = {\n                    \"id\": ins_key,\n                    \"appId\": result[\"appId\"],\n                    \"appComponentName\": result.get(\"appComponentName\", None),\n                    \"appInstanceId\": result[\"appInstanceId\"],\n                    \"appComponentInstanceId\": result.get(\"appComponentInstanceId\", None),\n                    \"cnt\": 1\n                }\n                data[ins_key] = item\n        else:\n            item = {\n                \"id\": ins_key,\n                \"appId\": result[\"appId\"],\n                \"appComponentName\": result.get(\"appComponentName\", None),\n                \"appInstanceId\": result[\"appInstanceId\"],\n                \"appComponentInstanceId\": result.get(\"appComponentInstanceId\", None),\n                \"cnt\": 1\n            }\n            data = {\n                ins_key: item\n            }\n            datas[def_key] = data\n\n    return datas\n\n\ndef get_results():\n    dt = datetime.datetime.now()\n    yesterday_dt = dt + datetime.timedelta(days=-1)\n    start_ds = yesterday_dt.strftime(\"%Y%m%d\")\n\n    now_day_dt = dt.replace(hour=0, minute=0, second=0, microsecond=0)\n    end_timestamp = int(now_day_dt.timestamp()) * one_second_millisecond\n    start_timestamp = end_timestamp - 86400000\n\n    definitions_dict = get_definitions_group_by_component()\n    ins_daily_dict = get_instances(start_timestamp, end_timestamp)\n    ins_dict = get_instances(None, None)\n\n    results = []\n    for def_key, instance_dict in ins_dict.items():\n        for ins_key, instance in instance_dict.items():\n            result = instance\n            result[\"defCnt\"] = definitions_dict[def_key][\"cnt\"]\n            result[\"instanceCnt\"] = instance[\"cnt\"]\n            result[\"instanceCntDailyAdditions\"] = ins_daily_dict.get(def_key, {}).get(ins_key, {}).get(\"cnt\", 0)\n            result[\"timestamp\"] = start_timestamp\n            result[\"ds\"] = start_ds\n\n            results.append(result)\n    return results\n\n\nprint(json.dumps(get_results()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 87,
        "type": "model",
        "layer": "dws"
      }
    }, {
      "id": 94,
      "gmtCreate": 1647512084200,
      "gmtModified": 1647591822011,
      "creator": "",
      "operator": "999999999",
      "appId": "",
      "name": "oem_app_incident_stats_1d",
      "alias": "应用天级别异常统计(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport datetime\nimport json\nimport requests\n\npage_size = 1000\none_second_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\nheaders = {}\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\"\n}\n\ncategory = \"incident\"\ninstance_path = {\n    \"risk\": \"/risk_instance/getRisks\",\n    \"alert\": \"/alert_instance/getAlerts\",\n    \"incident\": \"/incident_instance/getIncidents\",\n    \"failure\": \"/failure_instance/getFailures\"\n}\n\n\ndef get_definitions_group_by_component():\n    url = host[\"health\"] + \"/definition/getDefinitionsByCategory?category=\" + category\n    r = requests.get(url, headers=headers)\n    results = []\n    if r.status_code == 200:\n        results = r.json().get(\"data\", [])\n    datas = {}\n    for result in results:\n        key = result[\"appId\"]\n        if result.get(\"appComponentName\", None):\n            key = result[\"appId\"] + \"#\" + result[\"appComponentName\"]\n\n        if key in datas:\n            datas[key][\"cnt\"] += 1\n        else:\n            data = {\n                \"appId\": result[\"appId\"],\n                \"appComponentName\": result.get(\"appComponentName\", None),\n                \"cnt\": 1\n            }\n            datas[key] = data\n\n    return datas\n\n\ndef get_instances(s_timestamp, e_timestamp):\n    path = instance_path[category]\n    if s_timestamp is None and e_timestamp is None:\n        url = host[\"health\"] + path\n    else:\n        url = host[\"health\"] + path + \"?sTimestamp=\" + str(s_timestamp) + \"&eTimestamp=\" + str(e_timestamp)\n\n    r = requests.get(url, headers=headers)\n    results = []\n    if r.status_code == 200:\n        results = r.json().get(\"data\", [])\n    datas = {}\n    for result in results:\n        def_key = result[\"appId\"]\n        ins_key = result[\"appInstanceId\"]\n        if result.get(\"appComponentName\", None):\n            def_key = result[\"appId\"] + \"#\" + result[\"appComponentName\"]\n            ins_key = result[\"appInstanceId\"] + \"#\" + result[\"appComponentInstanceId\"]\n\n        if def_key in datas:\n            data = datas[def_key]\n            if ins_key in data:\n                data[ins_key][\"cnt\"] += 1\n            else:\n                item = {\n                    \"id\": ins_key,\n                    \"appId\": result[\"appId\"],\n                    \"appComponentName\": result.get(\"appComponentName\", None),\n                    \"appInstanceId\": result[\"appInstanceId\"],\n                    \"appComponentInstanceId\": result.get(\"appComponentInstanceId\", None),\n                    \"cnt\": 1\n                }\n                data[ins_key] = item\n        else:\n            item = {\n                \"id\": ins_key,\n                \"appId\": result[\"appId\"],\n                \"appComponentName\": result.get(\"appComponentName\", None),\n                \"appInstanceId\": result[\"appInstanceId\"],\n                \"appComponentInstanceId\": result.get(\"appComponentInstanceId\", None),\n                \"cnt\": 1\n            }\n            data = {\n                ins_key: item\n            }\n            datas[def_key] = data\n\n    return datas\n\n\ndef get_results():\n    dt = datetime.datetime.now()\n    yesterday_dt = dt + datetime.timedelta(days=-1)\n    start_ds = yesterday_dt.strftime(\"%Y%m%d\")\n\n    now_day_dt = dt.replace(hour=0, minute=0, second=0, microsecond=0)\n    end_timestamp = int(now_day_dt.timestamp()) * one_second_millisecond\n    start_timestamp = end_timestamp - 86400000\n\n    definitions_dict = get_definitions_group_by_component()\n    ins_daily_dict = get_instances(start_timestamp, end_timestamp)\n    ins_dict = get_instances(None, None)\n\n    results = []\n    for def_key, instance_dict in ins_dict.items():\n        for ins_key, instance in instance_dict.items():\n            result = instance\n            result[\"defCnt\"] = definitions_dict[def_key][\"cnt\"]\n            result[\"instanceCnt\"] = instance[\"cnt\"]\n            result[\"instanceCntDailyAdditions\"] = ins_daily_dict.get(def_key, {}).get(ins_key, {}).get(\"cnt\", 0)\n            result[\"timestamp\"] = start_timestamp\n            result[\"ds\"] = start_ds\n\n            results.append(result)\n    return results\n\n\nprint(json.dumps(get_results()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 88,
        "type": "model",
        "layer": "dws"
      }
    }, {
      "id": 95,
      "gmtCreate": 1647512084205,
      "gmtModified": 1647591810001,
      "creator": "",
      "operator": "999999999",
      "appId": "",
      "name": "oem_app_failure_stats_1d",
      "alias": "应用天级别故障统计(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport datetime\nimport json\nimport requests\n\npage_size = 1000\none_second_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\nheaders = {}\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\"\n}\n\ncategory = \"failure\"\ninstance_path = {\n    \"risk\": \"/risk_instance/getRisks\",\n    \"alert\": \"/alert_instance/getAlerts\",\n    \"incident\": \"/incident_instance/getIncidents\",\n    \"failure\": \"/failure_instance/getFailures\"\n}\n\n\ndef get_definitions_group_by_component():\n    url = host[\"health\"] + \"/definition/getDefinitionsByCategory?category=\" + category\n    r = requests.get(url, headers=headers)\n    results = []\n    if r.status_code == 200:\n        results = r.json().get(\"data\", [])\n    datas = {}\n    for result in results:\n        key = result[\"appId\"]\n        if result.get(\"appComponentName\", None):\n            key = result[\"appId\"] + \"#\" + result[\"appComponentName\"]\n\n        if key in datas:\n            datas[key][\"cnt\"] += 1\n        else:\n            data = {\n                \"appId\": result[\"appId\"],\n                \"appComponentName\": result.get(\"appComponentName\", None),\n                \"cnt\": 1\n            }\n            datas[key] = data\n\n    return datas\n\n\ndef get_instances(s_timestamp, e_timestamp):\n    path = instance_path[category]\n    if s_timestamp is None and e_timestamp is None:\n        url = host[\"health\"] + path\n    else:\n        url = host[\"health\"] + path + \"?sTimestamp=\" + str(s_timestamp) + \"&eTimestamp=\" + str(e_timestamp)\n\n    r = requests.get(url, headers=headers)\n    results = []\n    if r.status_code == 200:\n        results = r.json().get(\"data\", [])\n    datas = {}\n    for result in results:\n        def_key = result[\"appId\"]\n        ins_key = result[\"appInstanceId\"]\n        if result.get(\"appComponentName\", None):\n            def_key = result[\"appId\"] + \"#\" + result[\"appComponentName\"]\n            ins_key = result[\"appInstanceId\"] + \"#\" + result[\"appComponentInstanceId\"]\n\n        if def_key in datas:\n            data = datas[def_key]\n            if ins_key in data:\n                data[ins_key][\"cnt\"] += 1\n            else:\n                item = {\n                    \"id\": ins_key,\n                    \"appId\": result[\"appId\"],\n                    \"appComponentName\": result.get(\"appComponentName\", None),\n                    \"appInstanceId\": result[\"appInstanceId\"],\n                    \"appComponentInstanceId\": result.get(\"appComponentInstanceId\", None),\n                    \"cnt\": 1\n                }\n                data[ins_key] = item\n        else:\n            item = {\n                \"id\": ins_key,\n                \"appId\": result[\"appId\"],\n                \"appComponentName\": result.get(\"appComponentName\", None),\n                \"appInstanceId\": result[\"appInstanceId\"],\n                \"appComponentInstanceId\": result.get(\"appComponentInstanceId\", None),\n                \"cnt\": 1\n            }\n            data = {\n                ins_key: item\n            }\n            datas[def_key] = data\n\n    return datas\n\n\ndef get_results():\n    dt = datetime.datetime.now()\n    yesterday_dt = dt + datetime.timedelta(days=-1)\n    start_ds = yesterday_dt.strftime(\"%Y%m%d\")\n\n    now_day_dt = dt.replace(hour=0, minute=0, second=0, microsecond=0)\n    end_timestamp = int(now_day_dt.timestamp()) * one_second_millisecond\n    start_timestamp = end_timestamp - 86400000\n\n    definitions_dict = get_definitions_group_by_component()\n    ins_daily_dict = get_instances(start_timestamp, end_timestamp)\n    ins_dict = get_instances(None, None)\n\n    results = []\n    for def_key, instance_dict in ins_dict.items():\n        for ins_key, instance in instance_dict.items():\n            result = instance\n            result[\"defCnt\"] = definitions_dict[def_key][\"cnt\"]\n            result[\"instanceCnt\"] = instance[\"cnt\"]\n            result[\"instanceCntDailyAdditions\"] = ins_daily_dict.get(def_key, {}).get(ins_key, {}).get(\"cnt\", 0)\n            result[\"timestamp\"] = start_timestamp\n            result[\"ds\"] = start_ds\n\n            results.append(result)\n    return results\n\n\nprint(json.dumps(get_results()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 89,
        "type": "model",
        "layer": "dws"
      }
    }, {
      "id": 96,
      "gmtCreate": 1647512084213,
      "gmtModified": 1647592015082,
      "creator": "",
      "operator": "999999999",
      "appId": "",
      "name": "oem_app_health_stats_1d",
      "alias": "应用天级别健康统计(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport datetime\nimport json\nimport requests\n\npage_size = 1000\none_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\nheaders = {}\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\"\n}\n\ncategory_path_mapping = {\n    \"incident\": \"/incident_instance/getIncidents\",\n    \"failure\": \"/failure_instance/getFailures\",\n    \"risk\": \"/risk_instance/getRisks\",\n    \"alert\": \"/alert_instance/getAlerts\"\n}\n\n\ndef get_definitions_group_by_component(category):\n    url = host[\"health\"] + \"/definition/getDefinitionsByCategory?category=\" + category\n    r = requests.get(url, headers=headers)\n    results = []\n    if r.status_code == 200:\n        results = r.json().get(\"data\", [])\n    datas = {}\n    for result in results:\n        key = result[\"appId\"]\n        if key in datas:\n            datas[key][\"cnt\"] += 1\n        else:\n            data = {\n                \"appId\": result[\"appId\"],\n                \"cnt\": 1\n            }\n            datas[key] = data\n\n    return datas\n\n\ndef get_instances(category, s_timestamp, e_timestamp):\n    path = category_path_mapping[category]\n    if s_timestamp is None and e_timestamp is None:\n        url = host[\"health\"] + path\n    else:\n        url = host[\"health\"] + path + \"?sTimestamp=\" + str(s_timestamp) + \"&eTimestamp=\" + str(e_timestamp)\n\n    r = requests.get(url, headers=headers)\n    results = []\n    if r.status_code == 200:\n        results = r.json().get(\"data\", [])\n    datas = {}\n    for result in results:\n        def_key = result[\"appId\"]\n        ins_key = result[\"appInstanceId\"]\n        if def_key in datas:\n            data = datas[def_key]\n            if ins_key in data:\n                data[ins_key][\"cnt\"] += 1\n            else:\n                item = {\n                    \"id\": ins_key,\n                    \"appId\": result[\"appId\"],\n                    \"appInstanceId\": result[\"appInstanceId\"],\n                    \"cnt\": 1\n                }\n                data[ins_key] = item\n        else:\n            item = {\n                \"id\": ins_key,\n                \"appId\": result[\"appId\"],\n                \"appInstanceId\": result[\"appInstanceId\"],\n                \"cnt\": 1\n            }\n            data = {\n                ins_key: item\n            }\n            datas[def_key] = data\n\n    return datas\n\n\ndef get_results_by_category(category, now_day_dt):\n    end_timestamp = int(now_day_dt.timestamp()) * one_millisecond\n    start_timestamp = end_timestamp - 86400000\n\n    definitions_dict = get_definitions_group_by_component(category)\n    ins_daily_dict = get_instances(category, start_timestamp, end_timestamp)\n    ins_dict = get_instances(category, None, None)\n\n    results = {}\n    for def_key, instance_dict in ins_dict.items():\n        for ins_key, instance in instance_dict.items():\n            result = instance\n            result[category + \"DefCnt\"] = definitions_dict[def_key][\"cnt\"]\n            result[category + \"InstanceCnt\"] = instance[\"cnt\"]\n            result[category + \"InstanceCntDailyAdditions\"] = ins_daily_dict.get(def_key, {}).get(ins_key, {}).get(\"cnt\", 0)\n            result[\"timestamp\"] = start_timestamp\n\n            results[ins_key] = result\n    return results\n\n\ndef get_sla(now_day_dt):\n    end_timestamp = int(now_day_dt.timestamp()) * one_millisecond\n    start_timestamp = end_timestamp - 7 * 86400000\n\n    url = host[\"health\"] + \"/ocenter/getAppSla?sTimestamp=\" + str(start_timestamp) + \"&eTimestamp=\" + str(end_timestamp)\n    r = requests.get(url, headers=headers)\n    results = []\n    if r.status_code == 200:\n        results = r.json().get(\"data\", [])\n\n    return results\n\n\ndef get_results():\n    dt = datetime.datetime.now()\n    now_day_dt = dt.replace(hour=0, minute=0, second=0, microsecond=0)\n    start_timestamp = int(now_day_dt.timestamp()) * one_millisecond - 86400000\n\n    yesterday_dt = dt + datetime.timedelta(days=-1)\n    start_ds = yesterday_dt.strftime(\"%Y%m%d\")\n\n    risk_results = get_results_by_category(\"risk\", now_day_dt)\n    alert_results = get_results_by_category(\"alert\", now_day_dt)\n    incident_results = get_results_by_category(\"incident\", now_day_dt)\n    failure_results = get_results_by_category(\"failure\", now_day_dt)\n\n    sla_results = get_sla(now_day_dt)\n\n    all_app_instance_ids = set(risk_results.keys())\n    all_app_instance_ids.update(set(alert_results.keys()))\n    all_app_instance_ids.update(set(incident_results.keys()))\n    all_app_instance_ids.update(set(failure_results.keys()))\n\n    results = []\n    for app_instance_id in all_app_instance_ids:\n        risk = risk_results.get(app_instance_id, {})\n        alert = alert_results.get(app_instance_id, {})\n        incident = incident_results.get(app_instance_id, {})\n        failure = failure_results.get(app_instance_id, {})\n\n        app_id = \"\"\n        if risk:\n            app_id = risk.get(\"appId\")\n        if alert:\n            app_id = alert.get(\"appId\")\n        if incident:\n            app_id = incident.get(\"appId\")\n        if failure:\n            app_id = failure.get(\"appId\")\n\n        result = {\n            \"id\": app_instance_id,\n            \"appId\": app_id,\n            \"appInstanceId\": app_instance_id,\n            \"timestamp\": start_timestamp,\n            \"ds\": start_ds,\n            \"sla\": sla_results.get(app_instance_id, 1.0),\n            \"riskDefCnt\": risk.get(\"riskDefCnt\", 0),\n            \"alertDefCnt\": alert.get(\"alertDefCnt\", 0),\n            \"incidentDefCnt\": incident.get(\"incidentDefCnt\", 0),\n            \"failureDefCnt\": failure.get(\"failureDefCnt\", 0),\n            \"riskInstanceCnt\": risk.get(\"riskInstanceCnt\", 0),\n            \"alertInstanceCnt\": alert.get(\"alertInstanceCnt\", 0),\n            \"incidentInstanceCnt\": incident.get(\"incidentInstanceCnt\", 0),\n            \"failureInstanceCnt\": failure.get(\"failureInstanceCnt\", 0),\n            \"riskInstanceCntDailyAdditions\": risk.get(\"riskInstanceCntDailyAdditions\", 0),\n            \"alertInstanceCntDailyAdditions\": alert.get(\"alertInstanceCntDailyAdditions\", 0),\n            \"incidentInstanceCntDailyAdditions\": incident.get(\"incidentInstanceCntDailyAdditions\", 0),\n            \"failureInstanceCntDailyAdditions\": failure.get(\"failureInstanceCntDailyAdditions\", 0),\n        }\n        results.append(result)\n\n    return results\n\n\nprint(json.dumps(get_results()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 64,
        "type": "model",
        "layer": "ads"
      }
    }]
  },
  "sceneType": "collect",
  "sceneConf": {},
  "varConf": {},
  "notifyConf": null,
  "eventConf": []
}, {
  "id": 92,
  "gmtCreate": 1646306448585,
  "gmtModified": 1646306448585,
  "creator": "",
  "operator": "",
  "appId": "",
  "name": "oem_app_health_definition_collect",
  "alias": "应用健康定义采集作业(内置)",
  "tags": ["app", "health", "definition"],
  "description": null,
  "options": null,
  "triggerType": "cron",
  "triggerConf": {
    "cronExpression": "0 3 0 * * ? *",
    "enabled": true
  },
  "scheduleType": "serial",
  "scheduleConf": {
    "taskIdList": [{
      "id": 97,
      "gmtCreate": 1646306448567,
      "gmtModified": 1646306448567,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_risk_definition",
      "alias": "应用风险定义明细(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport json\nimport requests\n\nheaders = {}\n\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\"\n}\n\ncategory = \"risk\"\n\n\ndef getDefinitions():\n    url = host[\"health\"] + \"/definition/getDefinitionsByCategory?category=\" + category\n    r = requests.get(url, headers=headers)\n    result = []\n    if r.status_code == 200:\n        result = r.json().get(\"data\", [])\n\n    return result\n\n\nprint(json.dumps(getDefinitions()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 1,
        "type": "model",
        "layer": "dwd"
      }
    }, {
      "id": 98,
      "gmtCreate": 1646306448572,
      "gmtModified": 1646306448572,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_alert_definition",
      "alias": "应用告警定义明细(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport json\nimport requests\n\nheaders = {}\n\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\"\n}\n\ncategory = \"alert\"\n\n\ndef getDefinitions():\n    url = host[\"health\"] + \"/definition/getDefinitionsByCategory?category=\" + category\n    r = requests.get(url, headers=headers)\n    result = []\n    if r.status_code == 200:\n        result = r.json().get(\"data\", [])\n\n    return result\n\n\nprint(json.dumps(getDefinitions()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 3,
        "type": "model",
        "layer": "dwd"
      }
    }, {
      "id": 99,
      "gmtCreate": 1646306448576,
      "gmtModified": 1646306448576,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_incident_definition",
      "alias": "应用异常定义明细(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport json\nimport requests\n\nheaders = {}\n\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\"\n}\n\ncategory = \"incident\"\n\n\ndef getDefinitions():\n    url = host[\"health\"] + \"/definition/getDefinitionsByCategory?category=\" + category\n    r = requests.get(url, headers=headers)\n    result = []\n    if r.status_code == 200:\n        result = r.json().get(\"data\", [])\n\n    return result\n\n\nprint(json.dumps(getDefinitions()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 5,
        "type": "model",
        "layer": "dwd"
      }
    }, {
      "id": 100,
      "gmtCreate": 1646306448580,
      "gmtModified": 1646306448580,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_failure_definition",
      "alias": "应用故障定义明细(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport json\nimport requests\n\nheaders = {}\n\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\"\n}\n\ncategory = \"failure\"\n\n\ndef getDefinitions():\n    url = host[\"health\"] + \"/definition/getDefinitionsByCategory?category=\" + category\n    r = requests.get(url, headers=headers)\n    result = []\n    if r.status_code == 200:\n        result = r.json().get(\"data\", [])\n\n    return result\n\n\nprint(json.dumps(getDefinitions()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 7,
        "type": "model",
        "layer": "dwd"
      }
    }]
  },
  "sceneType": "collect",
  "sceneConf": {},
  "varConf": {},
  "notifyConf": null,
  "eventConf": []
}, {
  "id": 93,
  "gmtCreate": 1646306448662,
  "gmtModified": 1646306448662,
  "creator": "",
  "operator": "",
  "appId": "",
  "name": "oem_app_health_instance_collect",
  "alias": "应用健康实例采集作业(内置)",
  "tags": ["app", "health", "instance"],
  "description": null,
  "options": null,
  "triggerType": "cron",
  "triggerConf": {
    "cronExpression": "15 * * * * ? *",
    "enabled": true
  },
  "scheduleType": "serial",
  "scheduleConf": {
    "taskIdList": [{
      "id": 101,
      "gmtCreate": 1646306448639,
      "gmtModified": 1646306448639,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_risk_instance",
      "alias": "应用风险实例明细(内置)",
      "execTimeout": 60,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport time\nimport datetime\nimport json\nimport requests\n\nheaders = {}\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\"\n}\n\ncategory_path_mapping = {\n    \"incident\": \"/incident_instance/getIncidents\",\n    \"failure\": \"/failure_instance/getFailures\",\n    \"risk\": \"/risk_instance/getRisks\",\n    \"alert\": \"/alert_instance/getAlerts\"\n}\n\ncategory = \"risk\"\n\none_second_millisecond = 1000\none_minute_millisecond = 60000\n\n\ndef get_instances():\n    dt = datetime.datetime.now()\n    ds = dt.strftime(\"%Y%m%d\")\n\n    now_millisecond = int(time.time()) * one_second_millisecond\n    current_minute_timestamp = now_millisecond - now_millisecond % one_minute_millisecond\n    start_timestamp = current_minute_timestamp - one_minute_millisecond\n    end_timestamp = current_minute_timestamp\n\n    path = category_path_mapping[category]\n    url = host[\"health\"] + path + \"?sTimestamp=\" + str(start_timestamp) + \"&eTimestamp=\" + str(end_timestamp)\n\n    r = requests.get(url, headers=headers)\n    result = []\n    if r.status_code == 200:\n        result = r.json().get(\"data\", [])\n        for item in result:\n            item['ds'] = ds\n\n    return result\n\n\nprint(json.dumps(get_instances()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 2,
        "type": "model",
        "layer": "dwd"
      }
    }, {
      "id": 102,
      "gmtCreate": 1646306448644,
      "gmtModified": 1646306448644,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_alert_instance",
      "alias": "应用告警实例明细(内置)",
      "execTimeout": 60,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport time\nimport datetime\nimport json\nimport requests\n\nheaders = {}\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\"\n}\n\n\ncategory_path_mapping = {\n    \"incident\": \"/incident_instance/getIncidents\",\n    \"failure\": \"/failure_instance/getFailures\",\n    \"risk\": \"/risk_instance/getRisks\",\n    \"alert\": \"/alert_instance/getAlerts\"\n}\n\ncategory = \"alert\"\n\none_second_millisecond = 1000\none_minute_millisecond = 60000\n\n\ndef get_instances():\n    dt = datetime.datetime.now()\n    ds = dt.strftime(\"%Y%m%d\")\n\n    now_millisecond = int(time.time()) * one_second_millisecond\n    current_minute_timestamp = now_millisecond - now_millisecond % one_minute_millisecond\n    start_timestamp = current_minute_timestamp - one_minute_millisecond\n    end_timestamp = current_minute_timestamp\n\n    path = category_path_mapping[category]\n    url = host[\"health\"] + path + \"?sTimestamp=\" + str(start_timestamp) + \"&eTimestamp=\" + str(end_timestamp)\n\n    r = requests.get(url, headers=headers)\n    result = []\n    if r.status_code == 200:\n        result = r.json().get(\"data\", [])\n        for item in result:\n            item['ds'] = ds\n\n    return result\n\n\nprint(json.dumps(get_instances()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 4,
        "type": "model",
        "layer": "dwd"
      }
    }, {
      "id": 103,
      "gmtCreate": 1646306448651,
      "gmtModified": 1646306448651,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_incident_instance",
      "alias": "应用异常实例明细(内置)",
      "execTimeout": 60,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport time\nimport datetime\nimport json\nimport requests\n\nheaders = {}\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\"\n}\n\n\ncategory_path_mapping = {\n    \"incident\": \"/incident_instance/getIncidents\",\n    \"failure\": \"/failure_instance/getFailures\",\n    \"risk\": \"/risk_instance/getRisks\",\n    \"alert\": \"/alert_instance/getAlerts\"\n}\n\ncategory = \"incident\"\n\none_second_millisecond = 1000\none_minute_millisecond = 60000\n\n\ndef get_instances():\n    dt = datetime.datetime.now()\n    ds = dt.strftime(\"%Y%m%d\")\n\n    now_millisecond = int(time.time()) * one_second_millisecond\n    current_minute_timestamp = now_millisecond - now_millisecond % one_minute_millisecond\n    start_timestamp = current_minute_timestamp - one_minute_millisecond\n    end_timestamp = current_minute_timestamp\n\n    path = category_path_mapping[category]\n    url = host[\"health\"] + path + \"?sTimestamp=\" + str(start_timestamp) + \"&eTimestamp=\" + str(end_timestamp)\n\n    r = requests.get(url, headers=headers)\n    result = []\n    if r.status_code == 200:\n        result = r.json().get(\"data\", [])\n        for item in result:\n            item['ds'] = ds\n\n    return result\n\n\nprint(json.dumps(get_instances()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 6,
        "type": "model",
        "layer": "dwd"
      }
    }, {
      "id": 104,
      "gmtCreate": 1646306448656,
      "gmtModified": 1646306448656,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_failure_instance",
      "alias": "应用故障实例明细(内置)",
      "execTimeout": 60,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport time\nimport datetime\nimport json\nimport requests\n\nheaders = {}\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\"\n}\n\ncategory_path_mapping = {\n    \"incident\": \"/incident_instance/getIncidents\",\n    \"failure\": \"/failure_instance/getFailures\",\n    \"risk\": \"/risk_instance/getRisks\",\n    \"alert\": \"/alert_instance/getAlerts\"\n}\n\ncategory = \"failure\"\n\none_second_millisecond = 1000\none_minute_millisecond = 60000\n\n\ndef get_instances():\n    dt = datetime.datetime.now()\n    ds = dt.strftime(\"%Y%m%d\")\n\n    now_millisecond = int(time.time()) * one_second_millisecond\n    current_minute_timestamp = now_millisecond - now_millisecond % one_minute_millisecond\n    start_timestamp = current_minute_timestamp - one_minute_millisecond\n    end_timestamp = current_minute_timestamp\n\n    path = category_path_mapping[category]\n    url = host[\"health\"] + path + \"?sTimestamp=\" + str(start_timestamp) + \"&eTimestamp=\" + str(end_timestamp)\n\n    r = requests.get(url, headers=headers)\n    result = []\n    if r.status_code == 200:\n        result = r.json().get(\"data\", [])\n        for item in result:\n            item['ds'] = ds\n\n    return result\n\n\nprint(json.dumps(get_instances()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 8,
        "type": "model",
        "layer": "dwd"
      }
    }]
  },
  "sceneType": "collect",
  "sceneConf": {},
  "varConf": {},
  "notifyConf": null,
  "eventConf": []
}, {
  "id": 96,
  "gmtCreate": 1646306448804,
  "gmtModified": 1646306448804,
  "creator": "",
  "operator": "",
  "appId": "",
  "name": "oem_demoApp_user_order_failed_cnt_collect",
  "alias": "demApp每分钟用户订单失败数量采集作业(内置)",
  "tags": ["demoApp", "user_order_failed_cnt"],
  "description": null,
  "options": null,
  "triggerType": "cron",
  "triggerConf": {
    "cronExpression": "2 * * * * ? *",
    "enabled": true
  },
  "scheduleType": "serial",
  "scheduleConf": {
    "taskIdList": [{
      "id": 110,
      "gmtCreate": 1646306448799,
      "gmtModified": 1646306448799,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_demoApp_user_order_failed_cnt",
      "alias": "demoApp每分钟用户订单失败数(内置)",
      "execTimeout": 60,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport json\nimport time\nimport requests\nimport random\n\ndemo_app_id = \"sreworks1\"\none_second_millisecond = 1000\n\nheaders = {}\nhost = {\n    \"app\": \"http://prod-app-app.sreworks.svc.cluster.local:80\"\n}\n\n\ndef get_app_instances():\n    endpoint = host[\"app\"] + \"/appcenter/appInstance/allAppInstances?page=1&pageSize=1000000\"\n    r = requests.get(endpoint, headers=headers)\n    datas = r.json().get(\"data\", None)\n    app_instances = []\n    if datas:\n        for data in datas[\"items\"]:\n            if data[\"appId\"] == demo_app_id:\n                app_instances.append(data)\n    return app_instances\n\n\ndef build_metric_data():\n    app_instances = get_app_instances()\n    metric_datas = []\n    for app_instance in app_instances:\n        metric_data = {\n            \"timestamp\": int(time.time() * one_second_millisecond),\n            \"value\": random.randint(0, 8),\n            \"labels\": {\n                \"app_instance_id\": app_instance[\"appInstanceId\"],\n                \"app_instance_name\": app_instance[\"appInstanceName\"],\n                \"app_component_instance_id\": app_instance[\"appInstanceId\"],\n            }\n        }\n        metric_datas.append(metric_data)\n    return metric_datas\n\n\nprint(json.dumps(build_metric_data()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "true",
        "syncDw": "true",
        "id": 108,
        "type": "model",
        "relatedMetricId": 6,
        "layer": "dwd"
      }
    }]
  },
  "sceneType": "collect",
  "sceneConf": {},
  "varConf": {},
  "notifyConf": null,
  "eventConf": []
}, {
  "id": 97,
  "gmtCreate": 1646378426621,
  "gmtModified": 1646380217559,
  "creator": "999999999",
  "operator": "999999999",
  "appId": "",
  "name": "oem_pod_resource_allocated_collect",
  "alias": "POD资源分配明细采集作业(内置)",
  "tags": ["oem", "pod_resource_allocated"],
  "description": null,
  "options": null,
  "triggerType": "cron",
  "triggerConf": {
    "cronExpression": "0 * * * * ? *",
    "enabled": true
  },
  "scheduleType": "serial",
  "scheduleConf": {
    "taskIdList": [{
      "id": 111,
      "gmtCreate": 1646378306262,
      "gmtModified": 1646378306262,
      "creator": "999999999",
      "operator": "999999999",
      "appId": "",
      "name": "oem_app_pod_resource_allocated",
      "alias": "POD资源分配明细(内置)",
      "execTimeout": 60,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport datetime\nimport time\nimport json\nimport requests\n\nheaders = {}\nhost = {\n    \"dataset\": \"http://prod-dataops-dataset.sreworks-dataops.svc.cluster.local:80\"\n}\n\npage_size = 1000\none_second_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\n\ndef convert_utc_to_local_dt(str_utc_time):\n    # return datetime.datetime.strptime(str_utc_time, \"%Y-%m-%dT%H:%M:%S.%fZ\").replace(tzinfo=datetime.timezone.utc).astimezone(tz.tzlocal())\n    return datetime.datetime.strptime(str_utc_time, \"%Y-%m-%dT%H:%M:%S.%fZ\").replace(tzinfo=datetime.timezone.utc) \\\n        .astimezone(datetime.timezone(datetime.timedelta(hours=8)))\n\n\ndef _do_get_pod_resource_allocated(endpoint, start_timestamp, end_timestamp):\n    basic_url = f'''{endpoint}?sTimestamp={start_timestamp}&eTimestamp={end_timestamp}&pageSize={page_size}'''\n    page_num = 1\n    datas = []\n    while True:\n        url = basic_url + \"&pageNum=\" + str(page_num)\n        r = requests.get(url, headers=headers)\n        if r.status_code != 200:\n            break\n\n        ret = r.json().get(\"data\", None)\n        if ret and ret.get(\"datas\"):\n            datas.extend(ret.get(\"datas\"))\n            _total_num = int(ret.get(\"totalNum\"))\n            _page_size = int(ret.get(\"pageSize\"))\n            _page_num = int(ret.get(\"pageNum\"))\n            if _page_size > _total_num:\n                break\n            else:\n                page_num = _page_num + 1\n        else:\n            break\n\n    results = {}\n    for data in datas:\n        key = data[\"namespace\"] + \"#\" + data[\"podName\"]\n        if key not in results:\n            results[key] = data\n    return results\n\n\ndef get_pod_resource_allocated():\n    dt = datetime.datetime.now()\n    start_ds = dt.strftime(\"%Y%m%d\")\n    now_millisecond = int(time.time()) * one_second_millisecond\n    current_minute_timestamp = now_millisecond - now_millisecond % one_minute_millisecond\n    start_timestamp = current_minute_timestamp - one_minute_millisecond\n    end_timestamp = current_minute_timestamp\n\n    endpoint_cpu_core = host[\"dataset\"] + \"/interface/pod_cpu_core_hours_allocation\"\n    pod_cpu_core_allocation = _do_get_pod_resource_allocated(endpoint_cpu_core, start_timestamp, end_timestamp)\n\n    endpoint_ram_gb = host[\"dataset\"] + \"/interface/pod_ram_gb_hours_allocation\"\n    pod_ram_gb_allocation = _do_get_pod_resource_allocated(endpoint_ram_gb, start_timestamp, end_timestamp)\n\n    endpoint_pvc_gb = host[\"dataset\"] + \"/interface/pod_pvc_gb_hours_allocation\"\n    pod_pvc_gb_allocation = _do_get_pod_resource_allocated(endpoint_pvc_gb, start_timestamp, end_timestamp)\n\n    endpoint_cpu_usage = host[\"dataset\"] + \"/interface/pod_cpu_core_hours_usage_avg\"\n    pod_cpu_core_usage_avg = _do_get_pod_resource_allocated(endpoint_cpu_usage, start_timestamp, end_timestamp)\n\n    endpoint_ram_usage = host[\"dataset\"] + \"/interface/pod_ram_gb_hours_usage_avg\"\n    pod_ram_gb_usage_avg = _do_get_pod_resource_allocated(endpoint_ram_usage, start_timestamp, end_timestamp)\n\n    results = []\n    keys1 = set(pod_cpu_core_allocation.keys())\n    keys2 = set(pod_ram_gb_allocation.keys())\n    keys1.update(keys2)\n    for key in keys1:\n        result = pod_cpu_core_allocation.get(key, None)\n        if result is None:\n            result = pod_ram_gb_allocation.get(key, None)\n            result[\"podCpuCoreHoursAllocation\"] = 0\n        else:\n            result[\"podRamGbHoursAllocation\"] = pod_ram_gb_allocation.get(key, {}).get(\"podRamGbHoursAllocation\", 0)\n        result[\"podPVCGbHoursAllocation\"] = pod_pvc_gb_allocation.get(key, {}).get(\"podPVCGbHoursAllocation\", 0)\n        result[\"podCpuCoreHoursUsageAvg\"] = pod_cpu_core_usage_avg.get(key, {}).get(\"podCpuCoreHoursUsageAvg\", 0)\n        result[\"podRamGbHoursUsageAvg\"] = pod_ram_gb_usage_avg.get(key, {}).get(\"podRamGbHoursUsageAvg\", 0)\n        result[\"timestamp\"] = start_timestamp\n        result[\"id\"] = key + \"_\" + str(start_timestamp)\n        result[\"ds\"] = start_ds\n        results.append(result)\n\n    return results\n\n\nprint(json.dumps(get_pod_resource_allocated()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 109,
        "type": "model",
        "layer": "dwd"
      }
    }]
  },
  "sceneType": "collect",
  "sceneConf": {},
  "varConf": {},
  "notifyConf": null,
  "eventConf": []
}, {
  "id": 98,
  "gmtCreate": 1646638195021,
  "gmtModified": 1646638570841,
  "creator": "999999999",
  "operator": "999999999",
  "appId": "",
  "name": "oem_app_pod_status_collect",
  "alias": "应用POD状态明细采集作业",
  "tags": ["oem", "pod_status", "app"],
  "description": null,
  "options": null,
  "triggerType": "cron",
  "triggerConf": {
    "cronExpression": "25 * * * * ? *",
    "enabled": true
  },
  "scheduleType": "serial",
  "scheduleConf": {
    "taskIdList": [{
      "id": 113,
      "gmtCreate": 1646638544601,
      "gmtModified": 1646639742419,
      "creator": "999999999",
      "operator": "999999999",
      "appId": "",
      "name": "oem_app_pod_status",
      "alias": "应用POD状态明细(内置)",
      "execTimeout": 60,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport json\nimport time\nimport requests\n\nheaders = {}\n\npage_size = 1000\none_millisecond = 1000\none_minutes_millisecond = 60000\n\nhost = {\n    \"dataset\": \"http://prod-dataops-dataset.sreworks-dataops.svc.cluster.local:80\"\n}\n\n\ndef get_time_range(ts, delta_ts, forward_gap=0):\n    \"\"\"\n    时间范围\n    :param ts:\n    :param delta_ts:\n    :param forward_gap: 默认前推一个delta\n    :return:\n    \"\"\"\n    ts_integer = int(ts)\n    delta_ts_integer = int(delta_ts)\n\n    end_ts = ts_integer - ts_integer % delta_ts_integer\n    start_ts = end_ts - delta_ts_integer\n\n    delta_forward_ts_integer = delta_ts_integer * forward_gap\n\n    return start_ts - delta_forward_ts_integer, end_ts - delta_forward_ts_integer\n\n\ndef get_pod_status():\n    endpoint = host[\"dataset\"] + \"/interface/pod_status\"\n    start_timestamp, end_timestamp = get_time_range(time.time() * one_millisecond, one_minutes_millisecond)\n    basic_url = f'''{endpoint}?sTimestamp={start_timestamp}&eTimestamp={end_timestamp}'''\n\n    page_num = 1\n    pod_status_list = []\n    while True:\n        url = basic_url + \"&pageNum=\" + str(page_num)\n        r = requests.get(url, headers=headers)\n        if r.status_code != 200:\n            break\n\n        ret = r.json().get(\"data\", None)\n        if ret and ret.get(\"datas\"):\n            pod_status_list.extend(ret.get(\"datas\"))\n            _total_num = int(ret.get(\"totalNum\"))\n            _page_size = int(ret.get(\"pageSize\"))\n            _page_num = int(ret.get(\"pageNum\"))\n            if _page_size > _total_num:\n                break\n            else:\n                page_num = _page_num + 1\n        else:\n            break\n\n    for pod_status in pod_status_list:\n        pod_status[\"id\"] = pod_status[\"namespace\"] + \"_\" + pod_status[\"podName\"] + \"_\" + str(start_timestamp)\n        pod_status[\"podPhase\"] = pod_status[\"podStatus\"][\"phase\"]\n        pod_status[\"podReady\"] = pod_status[\"podStatus\"][\"ready\"]\n\n    return pod_status_list\n\n\nprint(json.dumps(get_pod_status()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 118,
        "type": "model",
        "layer": "dwd"
      }
    }]
  },
  "sceneType": "collect",
  "sceneConf": {},
  "varConf": {},
  "notifyConf": null,
  "eventConf": []
}]